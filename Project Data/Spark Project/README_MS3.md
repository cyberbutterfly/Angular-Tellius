**FEATURE TRANSFORM API**
 
 This api is used for ml specific transformation of columns. Every transformation takes one existing column and generates new column. 
 The type of the column plays important role in deciding is the column can be used for the transformation. So each section in the documentation
 will specify what should be the type of input column and what will be the expected type of output column.   

* Request URL : ml/featuretransform

This api takes following parameter,

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id   |Id of the source that has to be transformed| Yes |
| transformationtype |Type of the transformation | Yes |
| options     | These are custom options to be passed for the data source. For example, {"inputcolumn":"columnname"}     |  No |

Feature Transform API returns an id, later that id can be used to refer the transformed data.

```
{
  "id": "e0e9e53f-4d57-4a16-a9a0-656eb2473e9d"
}
```


**Transformation Type**

* **labelindexer**
    - Request URL : ml/featuretransform
    
    - Description
    
    Generates indexes for the string data. For example, if a given column has values "a,a,b,c,d" then it generates indexes as "0,0,1,2,3".
    
    - Options:
    
| Option Name        | Description          | Mandatory  | Column Type | 
| ------------- |:-------------:| -----:|---------:| 
| inputcolumn | name of the input column on which index has to be created| Yes | String,Numeric | 
| outputcolumn | name of the output column where index should get generated|Yes| Numeric |

  - Example Request

```
{
"id" :"$id",
"transformationtype":"labelindexer",
"options":{"inputcolumn":"state","outputcolumn":"indexstate"}
}
```

----

**Note**

In case of the null values in the inputcolumn specfied in labelindexer it will give the error message saying,

500 Internal Server Error.

This error can be expected when you try to view the data which was transformed.

----


* **featureindexer**

    - Request URL : ml/featuretransform
    - Description
     

    - options:
    
| Option Name        | Description          | Mandatory  | Column Type |
| ------------- |:-------------:| -----:|---------:|
| inputcolumn | name of the input columns on which index has to be created, separated by `,`.| Yes |Double|
| outputcolumn | name of the output column where index should get generated|Yes|Vector| 
| maxCategories | Threshold for the number of values a categorical feature can take (>= 2). If a feature is found to have > maxCategories values, then it is declared continuous. | No | 5|

- Example Request

```
{
"id" :"$id",
"transformationtype":"featureindexer",
"options":{"inputcolumn":"lat,long","outputcolumn":"indexcol","maxcategories":"32"}
}
```


In the above example lat and long are 2 numeric columns and the output column indexcol will be a column of vector type, which has the index for input columns.

----

**Note**

In case if the inputcolumn is of type string then it will give an error message saying,

StringType (of class org.apache.spark.sql.types.StringType$)

----


* **labelconverter**

    - Request URL : ml/featuretransform
    - Description
This API should only run on the dataset that is produced by the label indexer. This api takes column which has indexes generated by label indexer and produces the actual string data from those indexes.   

    - Options:
    
| Option Name        | Description          | Mandatory  |  Column Type 
| ------------- |:-------------:| -----:|---------:|
| inputcolumn | name of the input column | Yes | Numeric |
| outputcolumn | name of the output column|Yes|  String |

- Example Request
```
{
"id" :"$transformRequestId",
"transformationtype":"labelconverter",
"options":{"inputcolumn":"indexstate","outputcolumn":"stateLabels"}
}
```


* **vectorassembler**

    - Request URL : ml/featuretransform
    - Description
    
VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. VectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.

 - Options:
    
| Option Name        | Description          | Mandatory  |  Column Type 
| ------------- |:-------------:| -----:|---------:|
| inputcolumns | name of the input columns separated by comma | Yes | Numeric,Vector,Boolean |
| outputcolumn | name of the output column |Yes|  Vector |

Example : 

{
"id" :"featureTransformRequestId",
"transformationtype":"vectorassembler",
"options":{"inputcolumns":"age,fnlwgt,educationnum,capitalgain","outputcolumn":"vector_features"}
}


* **onehotencoder**

    * Request URL : ml/featuretransform
    * Parameters :
    * Description :

    A one-hot encoder that maps a column of category indices to a column of binary vectors, with at most a single one-value per row that indicates the input category index.


    * options:
    
| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
| inputcolumn | name of the input column | Yes | Numeric |
| outputcolumn | name of the output column|Yes|  String |

Example:

```
{
"id" :"featureTransformRequestId",
"transformationtype":"onehotencoder",
"options":{"inputcolumn":"indexstate","outputcolumn":"indexstate_vector"}
}
```

* **minmaxscaler**

    * Request URL : ml/featuretransform
    * Parameters :
    * Description :

    Rescale each feature individually to a common range [min, max] linearly using column summary statistics, which is also known as min-max normalization or Rescaling. 

 * options:
    
| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
| inputcolumn | name of the input column | Yes | Vector |
| outputcolumn | name of the output column|Yes|  Vector |
| min | lower bound after transformation | No | 0 |
| max | upper bound after transformation | No | 1 | 

Example:

```
{
"id" :"e0e9e53f-4d57-4a16-a9a0-656eb2473e9d",
"transformationtype":"minmaxscaler",
"options":{"inputcolumn":"vectorlat","outputcolumn":"scaledlat"}
}
```


To send the vector column as a input column first form a vector using vectorassembler feature transformation. If you want to scale more than one columns then send all those columns to vector assembler to get one single vector column. Which can be sent to the minmaxscaler


* **standardscaler**

    * Request URL : ml/featuretransform
    * Parameters :
    * Description :

    Standardizes features by removing the mean and scaling to unit variance using column summary statistics on the samples in the training set. 

 * options:
    
| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
| inputcolumn | name of the input column | Yes | Vector |
| outputcolumn | name of the output column|Yes|  Vector |
| withmean | Whether to center the data with mean before scaling | No | false |
| withstd | Whether to scale the data to unit standard deviation. | No | false|

Example:

```
{
"id" :"e0e9e53f-4d57-4a16-a9a0-656eb2473e9d",
"transformationtype":"standardscaler",
"options":{"inputcolumn":"vectorlat","outputcolumn":"scaledlat","withmean":"true"}
}
```

To send the vector column as a input column first form a vector using vectorassembler feature transformation. If you want to scale more than one columns then send all those columns to vector assembler to get one single vector column. Which can be sent to the minmaxscaler

* **multistringindexer**

    * Request URL : ml/featuretransform
    * Parameters :
    * Description :
     
    Its same as labelindexer. But it will take multiple columns and returns their index as an vector.

| Option Name        | Description          | Mandatory  | Column Type | 
| ------------- |:-------------:| -----:|---------:| 
| inputcolumns | name of the input columns on which index has to be created separated by `,`| Yes | String,Numeric | 
| outputcolumn | name of the output column where index should get generated|Yes| Vector |

Example:

```
{
"id" :"$id",
"transformationtype":"multistringindexer",
"options":{"inputcolumns":"airport,lat,long","outputcolumn":"vector"}
}
```


* **sampleratio**

    * Request URL : ml/featuretransform
    * Parameters :
    * options:
    
| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
| ratio | percentage of the whole data that has to be in sample data | No | 0.7 |

Example:

```
{
"sourceid" :"$id",
"transformationtype":"sampleratio",
"options":{"ratio":"0.7"}
}
```

returns,

```
{
  "id": "b702c5c6-b9db-43dd-a74e-bafb48bc8e64",
  "subsetsourceId": ["65aa5a5b-534f-46ca-b7fe-cccd8e9258c3"]
}
```
Where id is a dataframe with the ratio 0.7, and subsetsourceId is the dataframe with the 0.3 ratio of data.


**Feature Transform Update API**

   * Request URL : /ml/featuretransform/{requestId}
       - Here request id is the id of the request which has to be 
   * HTTP METHOD : PUT
   * options:

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id   |Id of the source that has to be transformed| Yes |
| transformationtype |Type of the transformation | Yes |
| options     | These are custom options to be passed.  |  No |

This request is similar to featuretransform request but its a put request and you have to specify the requestId in the url.

Example:

```
{
"id" :"e0e9e53f-4d57-4a16-a9a0-656eb2473e9d",
"transformationtype":"labelindexer",
"options":{"inputcolumn":"state","outputcolumn":"indexstateupdated"}
}
```

Response:

```
{
     "id": "f27d337a-62b1-4409-803f-8a50abb5748e"
}
```



**Trainmodel API**

This api is used to train the machine learning model on given dataset. All the columns of the dataset should be numerical in order to use them in this step. If they are not please use the above transformers to convert them to numerical values. 

- Request URL : ml/trainmodel

- Options

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id   | Id of the source that has to be trained| Yes |
| modelname | Name in which the model has to be saved, model can be referred by this name in future  | Yes |
| learningalgorithm | name of the algorithm on which model has to be built | Yes |
| options     | These are custom options to be passed for the training algorithm |  No |

Train model API returns an id and name  using which you can refer to the model in predict or pipeline API.

If the request is created to be used in the pipeline (using delay option) then the response will be only id which is used to pass to the pipeline API. At this stage the API will be lazy and will not compute anything.

```
{
  "id": "e0e9e53f-4d57-4a16-a9a0-656eb2473e9d"
}
```

If the request is to run the training of the model then response will not only contain id, it will also contain the name of the model. This indicates the actual training is executed and you can use this model in future steps.

```
{
  "id": "e0e9e53f-4d57-4a16-a9a0-656eb2473e9d",
  "modelname":"kmeanstest"
}
```

**Learning Algorithm**

* **linearregression **
    - Request URL : ml/trainmodel/regression
    - options:
    
| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. All columns should be numerical values | Yes|
| label| Name of the column which has to be considered as a label in model creation| Yes |
|numofiteration| Number of iteration that has to be done before creating a model | No | 20 |
|regparam | regularization parameter (>= 0)  | No  | 0.0 |
|elasticnetparam |the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.| No | 0.0|

Example:

```
{
"id" :"$id",
"modelname":"testregression",
"learningalgorithm":"linearregression",
"options":{"label":"long","featurescolumn":"lat"}
}
```

* logisticregression

    - Request URL : ml/trainmodel/classification
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. | Yes|
| label| Name of the column which has to be considered as a label in model creation.| Yes |
|maxIter|maximum number of iterations (>= 0) |No|100|
|regparam | regularization parameter (>= 0)  | No  | 0.0 |
|elasticnetparam |the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.| No | 0.0|
|tol|the convergence tolerance for iterative algorithms|No|1.0E-6|
|fitintercept|whether to fit an intercept term|No|true|
|weightcol|weight column name. If this is not set or empty, we treat all instance weights as 1.0.|No||
|standardization|whether to standardize the training features before fitting the model|No|true|
|threshold|threshold in binary classification prediction, in range [0, 1]|No|0.5|

Example:
```
{
"id" :"$indexerId",
"modelname":"testlogisticregression",
"learningalgorithm":"logisticregression",
"options":{"label":"fieldindex","featurescolumn":"field2"}
}
```


* decisiontreeclassifier

    - Request URL : ml/trainmodel/classification
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. | Yes|
| label| Name of the column which has to be considered as a label in model creation.| Yes |
|maxdepth|Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.|No|10|
|maxbins|Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. |No|32|
|impurity|Criterion used for information gain calculation (case-insensitive). Supported options: variance|No|gini|

Example:
```
{
"id" :"$indexerId",
"modelname":"testdecisiontreeclassifier",
"learningalgorithm":"decisiontreeclassifier",
"options":{"label":"fieldindex","featurescolumn":"field2"}
}
```

* randomforestclassifier

    - Request URL : ml/trainmodel/classification
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. | Yes|
| label| Name of the column which has to be considered as a label in model creation.| Yes |
|numtrees|Number of trees to train (>= 1) |No|20|
|maxdepth|Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.|No|10|
|maxbins|Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. |No|32|
|impurity|Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini |No|gini|
|subsamplingRate|Fraction of the training data used for learning each decision tree, in range (0, 1]. |No|1|
|featureSubsetStrategy|The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2 |No|auto|

Example:
```
{
"id" :"$indexerId",
"modelname":"testrandomforestclassifier",
"learningalgorithm":"randomforestclassifier",
"options":{"label":"fieldindex","featurescolumn":"field2"}
}
```
* randomforestregressor

    - Request URL : ml/trainmodel/regression
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. | Yes|
| label| Name of the column which has to be considered as a label in model creation.| Yes |
|numtrees|Number of trees to train (>= 1) |No|20|
|maxdepth|Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.|No|10|
|maxbins|Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. |No|32|
|impurity|Criterion used for information gain calculation (case-insensitive). Supported options: variance |No|variance|
|subsamplingRate|Fraction of the training data used for learning each decision tree, in range (0, 1]. |No|1|
|featureSubsetStrategy|The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2 |No|auto|

Example:
```
{
"id" :"$indexerId",
"modelname":"testrandomforestregressor",
"learningalgorithm":"randomforestregressor",
"options":{"label":"fieldindex","featurescolumn":"field2"}
}
```


* gbtclassifier

    - Request URL : ml/trainmodel/classification
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. | Yes|
| label| Name of the column which has to be considered as a label in model creation.| Yes |
|maxIter|maximum number of iterations (>= 0) |No|20|
|maxdepth|Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.|No|10|
|maxbins|Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. |No|32|
|impurity|Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini |No|gini|
|lossType|Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic |No|logistic|
|stepSize|Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator |No|0.1|
|subsamplingRate|Fraction of the training data used for learning each decision tree, in range (0, 1]. |No|1.0|

Example:
```
{
"id" :"$indexerId",
"modelname":"testgbtclassifier",
"learningalgorithm":"gbtclassifier",
"options":{"label":"fieldindex","featurescolumn":"field2"}
}
```


* decisiontreeregressor

    - Request URL : ml/trainmodel/regression
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. This should be double value. | Yes|
| label| Name of the column which has to be considered as a label in model creation, should be a double value| Yes |
|maxdepth|Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.|No|10|
|maxbins|Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. |No|32|
|impurity|Criterion used for information gain calculation (case-insensitive). Supported options: variance|No|gini|

Example:
```
{
"id" :"$indexerId",
"modelname":"testdecisiontree",
"learningalgorithm":"decisiontreeregressor",
"options":{"label":"fieldindex","featurescolumn":"field2"}
}
```

* gbtregressor 

    - Request URL : ml/trainmodel/regression
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. This should be double value. | Yes|
| label| Name of the column which has to be considered as a label in model creation, should be a double value| Yes |
|maxIter|maximum number of iterations (>= 0)|No|20|
|maxdepth|Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.|No|5|
|maxbins|Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. |No|32|
|impurity|Criterion used for information gain calculation (case-insensitive). Supported options: variance|No|variance|
|lossType|Loss function which GBT tries to minimize (case-insensitive). Supported options: squared, absolute|No|squared|
|stepSize|Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator |No|0.1|
|subsamplingRate|Fraction of the training data used for learning each decision tree, in range (0, 1]. |No|1.0|

Example:
```
{
"id" :"$indexerId",
"modelname":"testgbtregressor",
"learningalgorithm":"gbtregressor",
"options":{"label":"fieldindex","featurescolumn":"field2"}
}
```


* ridgeregressionwithsgd

    - Request URL : ml/trainmodel/regression
    - options:
    
| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. This should be double value. | Yes|
| label| Name of the column which has to be considered as a label in model creation, should be a double value| Yes |
|numofiteration| Number of iteration that has to be done before creating a model | No | 20 |
|regparam | regularization parameter (>= 0)  | No  | 0.0 |
|elasticnetparam |the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.| No | 0.0|

Example:

```
{
"id" :"$id",
"modelname":"testridgeregressionwithsgd",
"learningalgorithm":"ridgeregressionwithsgd",
"options":{"label":"long","featurescolumn":"lat"}
}
```

* kmeans

    - Request URL : ml/trainmodel/clustering
    - options:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. This should be double value. | Yes|
| numclusters | number of clusters to create  |No | 2|
|initializationmode | initialization algorithm  | No| `k-means||` |
|initializationsteps| number of steps for `k-means||` |No| 5|
|maxiteration|maximum number of iterations |No|20|
|tol|the convergence tolerance for iterative algorithms|No|0.0004|

Example : 
```
{
"id" :"$indexerId",
"modelname":"testkmeans",
"learningalgorithm":"kmeans",
"options":{"featurescolumn":"field2","initializationmode":"random"}
}
```

* Generic option for all the trainmodel api's

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
| delay | It will do the execution when the id is used in the pipeline api, when we just run trainmodel its a lazy operation and it will just return id.| No | Nothing|

If in the trainmodel api if the delay option is set then the actual execution is behold till that id is used in the pipeline API.


Example: 

```
{
"id" :"$indexerId",
"modelname":"testkmeans",
"learningalgorithm":"kmeans",
"options":{"featurescolumn":"field2","initializationmode":"random","delay":"true"}
}
```


**TrainModel List API**

  * Request URL : ml/trainmodel/list/{id}
  * Description
This api is used to list all the details of the trainmodel request which is identified by id.
  

Example Request:

```
ml/trainmodel/list/16cf8a56-a55a-43d1-999b-942e1dfe4986
```

Response : 

```
{
  "trainModelRequest": {
    "id": "befcabff-237d-4bf1-94d2-a4f5f57fc44d",
    "modelname": "testkmeans-357001609217531",
    "learningalgorithm": "kmeans",
    "options": {
      "featurescolumn": "field2",
      "initializationmode": "random"
    }
  },
  "featureTransformRequests": [{
    "id": "ccc11c47-9ad2-4156-a5bf-4de9e1bfd73b",
    "transformationtype": "labelindexer",
    "options": {
      "inputcolumn": "field3",
      "outputcolumn": "fieldindex1"
    }
  }, {
    "id": "7bb424bc-24e0-4d3a-bc6b-058944972af6",
    "transformationtype": "labelindexer",
    "options": {
      "inputcolumn": "field1",
      "outputcolumn": "fieldindex"
    }
  }]
}
```

----

**Note**

Response will have train model request and feature transform requests used for the input of the model.

----



Here id represents the id of the source on which model has to be created.

**Train Model update API**

  * Request URL : /ml/trainmodel/kmeans/{requestId}
    
    here requestId is the id of the request to be updated 
  
  * HTTP METHOD : put
  * Description : 
This API is used to update the trainmodel request which is already there. You can update all the request parameters except modelName.
  * Parameters :

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id | Id of the source that has to be trained. | No |
| learningalgorithm | name of the algorithm on which model has to be built | Yes |
| options     | These are custom options to be passed for the training algorithm |  Yes |


Example:

```
{
  "id":"900156a9-b777-47dc-ba48-16ab290fc66b",
  "learningalgorithm": "decisiontreeclassifier",
  "options": {
    "label": "newLabel",
    "featurescolumn":"features"
  }
}
```

----

**Note**

Here id represents the id of the source on which model has to be created.

Response of this api is same response as of trainmodel api.

When you run the trainmodel update api, it will be generating new model with the new parameters. If there is a old model in that path, then it will be deleted.

----


**Predict API**

- Request URL : ml/predict
- Description
This api is used to predict the labels from the data of features using the model created.Data given to this api should only contain the columns which are used as the features in the model creation, and in the exact same order.
- Parameters

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id   |Id of the source that has to be predicted| Yes |
| modelname | name of the model using which prediction has to be performed.(name given in train model API)| Yes |
| options     | These are custom options to be passed |  No |

 - options:
    
| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which should be in a same sequence as it was in the time during model creation | Yes|
| label| Name of the column which has to be considered as a label in model creation | No | |

* If the predict API is not having the option label then the label column and residual will not be present in the predicted output.
* If the predict API is for any regression model, then residual column will be there in the predict output. If it for classification then residual column will not be there.

Example : 

```
{
"id" :"900156a9-b777-47dc-ba48-16ab290fc66b",
"modelname":"testdecisiontree",
"options":{
        "featurescolumn":"features",
        "label":"index_salary"
    }
}
```


This Api returns the id of the dataframe which will have the features and prediction column. Using view API on the id returned by predict API data can be viewed.

```
{
  "id": "e0e9e53f-4d57-4a16-a9a0-656eb2473e9d"
}
```

* When we call view on the output of the predict api, and the model is regression model then it'll look like, It will have residual column.

Example : 
``` 
{
  "data": [
    {
      "features": "[0,1,1,0]",
      "index_salary": "2.3",
      "prediction":"2.1",
      "residual": "0.2"
    },
    {
      "features": "[0,1,2,0]",
      "index_salary": "3.5",
      "prediction":"3.2",
      "residual": "0.3"
    }]
}

```


* When we call view on the output of the predict api, and the model is classification model then it'll look like, It will not have residual column.

Example : 
``` 
{
  "data": [
    {
      "features": "[0,1,1,0]",
      "index_salary": "2.3",
      "prediction":"2.1"
    },
    {
      "features": "[0,1,2,0]",
      "index_salary": "3.5",
      "prediction":"3.2"
    }]
}

```


**Note**

* Scenario 1 : Model has been created using ml/trainpipeline

    * Source to Predict API would be raw data provided as source to the trainpipeline
    * Example :
    ```
    {
    "id" :"900156a9-b777-47dc-ba48-16ab290fc66b",
    "modelname":"testdecisiontree",
    "options":{
            "featurescolumn":"features"
        }
    }
    ```
     
* Scenario 2 : Model has been created using ml/trainmodel
 
    * Source to Predict API would be resultant data of all ml/featuretransformations performed
    * Example :
        ```
        {
        "id" :"900156a9-b777-47dc-ba48-16ab290fc66b",
        "modelname":"testdecisiontree",
        "options":{
                "featurescolumn":"features"
            }
        }
        ```
     
  
    

**Pipeline API**

This api is used to pipe the different transformation and models

* Request URL : ml/trainpipeline
This api takes following parameter,

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id   |Id of the source that has to be transformed and used to create model| Yes |
| pipelineids | id's of the transformation and model request | Yes | 
| modelname | name of the model using which prediction has to be performed.(name given in train model API)| Yes |
|options|options specific to the pipeline| No |



The following section depicts the steps to create a pipleline. Please note pipeline
is strict about column names and the order.

Step 1 : Create indexer for label, returns $indexerId

Step 2 : Create vector assembler to create vector from input columns for the training model. You
must name the output column as features. This return $vectorAssemblerId

Step 3 : Create Train model request with delay=true. Pass input column as features and label
as name of the column you want to use as label. This returns $trainId

Please note that vectorizing all input columns is must
for running training in pipeline.

Once you have the id's from above steps,

Example : 
```
{
"id" :"$id",
"pipelineids":"$indexerId,$vectorAssemblerId,$trainId",
"modelname":"testing"
}
```

train pipeline API returns an id and name of the mode which can be refered by predict and evaluate

```
{
  "id": "e0e9e53f-4d57-4a16-a9a0-656eb2473e9d"
  "modelname::"testing"
}
```

**Evaluator API**

This API is used to do model evaluation is done on test data.

* Request URL : /ml/evaluatemodel

This API takes following parameters,

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id   |Id of the test source which should be used to test against model| Yes |
| modelname | name of the model which has to be evaluated.(name given in train model API)| Yes |
| evaluator | Type of evluator that compute metric from predictions | Yes |
| options | Based on the evaluators these options will change | Yes |


* evaluator : Following are the valid values for evaluator
    - regressionevaluator
    - classificationevaluator

* options : Following are the valid options.

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|featurescolumn | name of the columns separated by , which has to be considered as features in model creation. This should be double value. | Yes|
| label| Name of the column which has to be considered as a label in model creation, should be a double value| Yes |
| metric | Metric on which the model has to be evaluated | Yes |  |
| threshold | takes the vaalue of prediction threshold. This is applicable only for metrics recall and precision | No | |
| numBins | Number of bins for roc curve | No |100|


* metric : Metric values changes based on evaluator, valid metric values are,
    - regressionevaluator : featurecolumns,rmse,mse,r2,mae,modelstring (only for decisiontreeregressor,decisiontreeclassifier), featureimportance(only for randomforestregressor)
    - classificationevaluator : featurecolumns,areaUnderROC,areaUnderPR,TP,FP,F1,recall,precision,confusionMatrix,modelstring (only for decisiontreeclassifier,randomForestClassifier) ,roccurve, featureimportance(only for randomforestclassifier)

Evaluate API returns the metric and the result of evaluation as a response.

Example: 
```
{
"id" :"$indexerId",
"modelname":"$modelName",
"evaluator":"classificationevaluator",
"options":{"featurescolumn":"field2","label":"fieldindex","metric":"areaUnderROC"}
}
```

Response will be like,

```
{
  "measures": {
    "areaUnderROC": 0.6666666666666666
  }
}
```

Example :
  
```
{
"id" :"$indexerId",
"modelname":"$modelName",
"evaluator":"classificationevaluator",
"options":{"featurescolumn":"field2,field3","label":"fieldindex","metric":"roccurve"}
}
```

Response:

```
{
  "measures": {
    "falsePositiveRate": "0.0,0.0,0.0,0.0,1.0,1.0",
    "truePositivieRate": "0.0,0.3333333333333333,0.6666666666666666,1.0,1.0,1.0"
  }
}
```
Example(confusionMatrix) :

```
{
"id" :"$indexerId",
"modelname":"$modelName",
"evaluator":"classificationevaluator",
"options":{"featurescolumn":"field2,field3","label":"fieldindex","metric":"confusionMatrix"}
}
```

Response:

```
{
  "measures": {
    "confusionMatrix": "1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0"
  }
}
```

Example(featurecolumns) : 

```
{
    "id" :"$indexerId",
    "modelname":"$modelName",
    "evaluator":"classificationevaluator",
    "options":{"metric":"featurecolumns"}
}
```

Response:

```
{
  "measures": {
    "featurecolumns": "Mileage,Cylinder,Liter,type_encoded-0,type_encoded-1,type_encoded-2,type_encoded-3,type_encoded-4"
  }
}
```



**Note**
    
   * featurecolumns returns the list of columns using which the model was trained.
   * The values in the confusionMatrix are stored columnwise from the generated metric value.
   * For example if the confusion matrix (categorical label of 2 classes) contains below 4 values   :
   * 11702.0  733.0
   * 2550.0   1296.0

   * confusionMatrix  metric value will be: 11702.0,2550.0,733.0,1296.0 

Evaluate model can use the `subsetsourceId` which is returned by the sample API. In this way sample of the data will be evaluated against the model. 

Example for modelstring:

```
{
"id" :"$indexerId",
"modelname":"$modelName",
"evaluator":"classificationevaluator",
"options":{"featurescolumn":"field2","label":"fieldindex","metric":"modelstring"}
}
```

Response:

```
{
  "measures": {
    "modelstring": "DecisionTreeClassificationModel of depth 3 with 7 nodes  If (feature 0 <= 100.0)\n   Predict: 2.0\n  Else (feature 0 > 100.0)
    If (feature 0 <= 200.0)\n    Predict: 1.0\n   Else (feature 0 > 200.0)\n    If (feature 0 <= 300.0)\n     Predict: 3.0\n    Else (feature 0 > 300.0)\n     Predict: 0.0\n"
  }
}
```


**Note**

* Scenario 1 : Model has been created using ml/trainpipeline

    * Source to Evaluator API would be raw data provided as source to the trainpipeline
    * Example :
    ```
    {
        "id" :"$loadId",
        "modelname":"$modelName",
        "evaluator":"classificationevaluator",
        "options":{"featurescolumn":"features","label":"label","metric":"modelstring"}
    }
    ```
     
* Scenario 2 : Model has been created using ml/trainmodel
 
    * Source to Evaluator API would be resultant data of all ml/featuretransformations performed
    * Example :
        
    ```
    {
        "id" :"$indexerId",
        "modelname":"$modelName",
        "evaluator":"classificationevaluator",
        "options":{"featurescolumn":"features","label":"label","metric":"modelstring"}
    }
    ```
     



**Compare API**

This API is used to compare 2 models based on given metrics.

* Request URL : /ml/compare

This API takes following parameters : 

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id   |Id of the test source which should be used to test against model| Yes |
| modelname | name of the model which has to be compared.(name given in train model API)| Yes |
| comparemodelname | name of the model which has to be compared.(name given in train model API)| Yes |
| evaluator | Type of evluator that compute metric from predictions | Yes |
| options | Based on the evaluators these options will change | Yes |

evaluator and options values are same as evaluator API.

Example : 

```
{
"id" :"$indexerId",
"modelname":"modelName",
"comparemodelname":"secondModelName",
"evaluator":"classificationevaluator",
"options":{"featurescolumn":"field2","label":"fieldindex","metric":"precision,recall"}
}
```

Response : 

```
{
  "measures": {
    "modelName": {
      "precision": 1.0,
      "recall": 1.0
    },
    "secondModelName": {
      "precision": 1.0,
      "recall": 1.0
    }
  }
}
```


**Cross Validation API**

CrossValidator begins by splitting the dataset into a set of folds which are used as separate training and test datasets.

For each of the datasets it creates a model and evaluate through given evaluator.


* Request URL : /ml/crossvalidation

This API takes following parameters : 

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| id | Id of the datasource| Yes|
| pipelineid | Id of the pipeline to which model has to be created | Yes |
| modelname | Name that should be given to the model | Yes |
| evaluator | Type of evluator that compute metric from predictions, refer evaluator api for details | Yes |
| options | Based on the evaluators these options will change and some other options, for evaluator based options refer evaluator api | Yes |

* options : Following are the valid options.

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
| folds | Number of fold used to select the best model. with k=3 folds, CrossValidator will generate 3 (training, test) dataset pairs, each of which uses 2/3 of the data for training and 1/3 for testing (default: 2) | No | 2 |


* Along with this option you can specify the parameters for specific model type. As you were sending in the trainmodel api.

Example1 :

```
{
"id" :"e0e9e53f-4d57-4a16-a9a0-656eb2473e9d",
"pipelineid":"pipelineId",
"modelname":"decisiontreeModelForCrossValidation",
"evaluator":"regressionevaluator",
"options":{"maxdepth":"10",
            "maxbins":"32",
            "folds":"3"}
}
```

Example2:

```
"id" :"e0e9e53f-4d57-4a16-a9a0-656eb2473e9d",
"pipelineid":"pipelineId",
"modelname":"randomforestModelforCrossValidation",
"evaluator":"classifierevaluator",
"options":{"maxdepth":"10",
            "maxbins":"32",
            "numtrees":"30",
            "subsamplingRate":"0.5",
            "folds":"3"}
}
```

Response:

```
{
  "id": "crossValidationModel-416157055901923"
}
```

Response contains name of the model.

As of now there is an issue from the spark side in labelindexer. It is fixed in spark version 1.6.0.

For more details about the issue refer https://issues.apache.org/jira/browse/SPARK-8764

**ML list API**

This API will help us to view all the models generated. 

* Request URL : /ml/list

This API takes following parameters : 

ML List api takes following parameters,

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| options | It will change, based on what you are trying to list requests| Yes | 

Valid options are:

| Option Name        | Description          | Mandatory  | Default Value |
| ------------- |:-------------:| -----:|---------:|
|modelnames| It takes comma separated values of names of models which you want to listcor "all" |No| all |

Example:

```
{
   "options" : {"modelnames" : "modelName"}
}
```

Response:

```
{
  "results": [
    {
      "modelname": "car_prices_regression",
      "learningalgorithm": "linearregression",
      "createdBy":"testUser",
      "algorithmtype":"regression",
      "options": {
        "label": "label",
        "featurescolumn": "features",
        "delay": "true"
      },
      "evaluationMetric": {
        "rmse": "230.8143505401066",
        "mse": "53275.264415251215",
        "r2": "0.010350402768280587",
        "mae": "199.2880771985701"
      }
    }
  ]
}
```

**createdBy** specifies the username of the user who created the model.
**algorithmtype** specified the type of the algorithm (classification, regression or clustering).


**ML delete API**

This API is used to delete the ML model

* Request URL : /ml/delete


ML delete api takes following parameters,

| Name        | Description          | Mandatory  |
| ------------- |:-------------:| -----:|
| modelname | Name of the model which has to be deleted | Yes |
 
 
Example:


```
{
   "modelname" : "linear_regression_model"
}
```

Response when successfully deleted:

```
{
  "deleted": true
}
```


Response when delete failed:

```
{
  "deleted": true,
  "reason": "requirement failed: model with name linear_regression_model not found"
}
```
